{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed50409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Imports\n",
    "from __future__ import annotations\n",
    "import os, random, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Subset\n",
    "import torch.nn.functional as F\n",
    "import mediapipe as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "463f3eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "► Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# 1. Paths & device\n",
    "SCRIPT_DIR    = Path().resolve()\n",
    "DATA_ROOT     = SCRIPT_DIR/\"Data-REHAB24-6\"\n",
    "WIN_CSV       = DATA_ROOT/\"Segmentation_windows.csv\"\n",
    "KEYPT_ROOT    = DATA_ROOT/\"mp_keypoints\"\n",
    "\n",
    "DEVICE = (\n",
    "    torch.device(\"mps\") if torch.backends.mps.is_available() else\n",
    "    torch.device(\"cuda\") if torch.cuda.is_available() else\n",
    "    torch.device(\"cpu\")\n",
    ")\n",
    "print(\"► Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97531384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOINT_NAMES: ['NOSE', 'LEFT_EYE_INNER', 'LEFT_EYE', 'LEFT_EYE_OUTER', 'RIGHT_EYE_INNER', 'RIGHT_EYE', 'RIGHT_EYE_OUTER', 'LEFT_EAR', 'RIGHT_EAR', 'MOUTH_LEFT', 'MOUTH_RIGHT', 'LEFT_SHOULDER', 'RIGHT_SHOULDER', 'LEFT_ELBOW', 'RIGHT_ELBOW', 'LEFT_WRIST', 'RIGHT_WRIST', 'LEFT_PINKY', 'RIGHT_PINKY', 'LEFT_INDEX', 'RIGHT_INDEX', 'LEFT_THUMB', 'RIGHT_THUMB', 'LEFT_HIP', 'RIGHT_HIP', 'LEFT_KNEE', 'RIGHT_KNEE', 'LEFT_ANKLE', 'RIGHT_ANKLE', 'LEFT_HEEL', 'RIGHT_HEEL', 'LEFT_FOOT_INDEX', 'RIGHT_FOOT_INDEX']\n",
      "N_JOINTS: 33\n"
     ]
    }
   ],
   "source": [
    "# 2. Joint names & count\n",
    "PoseLandmark = mp.solutions.pose.PoseLandmark\n",
    "\n",
    "# Then:\n",
    "JOINT_NAMES = [lm.name for lm in PoseLandmark]\n",
    "N_JOINTS    = len(JOINT_NAMES)  # should be 33\n",
    "\n",
    "print(f\"JOINT_NAMES: {JOINT_NAMES}\")\n",
    "print(f\"N_JOINTS: {N_JOINTS}\")\n",
    "\n",
    "#  Exerciseses (Ex1…Ex6)\n",
    "NUM_EXERCISES = 6\n",
    "CKPT_FILE     = \"kp_pose_quality_windows_ex.pt\"  \n",
    "\n",
    "ERR_JOINTS   = [\n",
    "  \"LEFT_ELBOW\",\"RIGHT_ELBOW\",\n",
    "  \"LEFT_SHOULDER\",\"RIGHT_SHOULDER\",\n",
    "  \"LEFT_HIP\",\"RIGHT_HIP\",\n",
    "  \"LEFT_KNEE\",\"RIGHT_KNEE\",\n",
    "  \"SPINE\",\"HEAD\",\n",
    "]\n",
    "N_ERR = len(ERR_JOINTS)   # 10\n",
    "ERR_COLS = [f\"err_{i}\" for i in range(N_ERR)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a911cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET\n",
    "class KeypointWindowDataset(Dataset):\n",
    "    def __init__(self, csv_file: Path, keypt_root: Path):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df = df.sort_values([\"video_id\",\"repetition_number\",\"window_start\"])\n",
    "        self.rows = df.to_dict(\"records\")\n",
    "        self.keypt_root = keypt_root\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, i: int):\n",
    "        r   = self.rows[i]\n",
    "        ex  = int(r[\"exercise_id\"]) - 1      # zero‐based [0..NUM_EXERCISES-1]\n",
    "        vid = r[\"video_id\"]\n",
    "        f0, f1 = int(r[\"window_start\"]), int(r[\"window_end\"])\n",
    "\n",
    "        # load keypoints\n",
    "        arr = np.load(\n",
    "            next((self.keypt_root/f\"Ex{ex+1}\").glob(f\"{vid}-Camera17*-mp.npy\"))\n",
    "        )  # shape (F,33,3)\n",
    "\n",
    "        seg = arr[f0:f1]            # (T, 33, 3)\n",
    "        seg = seg.reshape(len(seg), -1)  # (T, 99)\n",
    "        seq = torch.from_numpy(seg).float()\n",
    "\n",
    "        label = torch.tensor(r[\"correctness\"], dtype=torch.long)\n",
    "        err   = torch.tensor([r[f\"err_{j}\"] for j in range(N_ERR)],\n",
    "                             dtype=torch.float32)\n",
    "\n",
    "        return seq, label, err, ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71a49b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Model definitions\n",
    "class KeypointEncoder(nn.Module):\n",
    "    def __init__(self, in_dim:int, embed:int=512):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_dim, 128, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(128, embed, kernel_size=3, padding=1)\n",
    "        self.pool  = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B, D); treat as (B, D, 1) for Conv1d\n",
    "        x = x.unsqueeze(2)                 # → (B, D, 1)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        return self.pool(x).squeeze(-1)    # → (B, embed)\n",
    "\n",
    "class PoseQualityNetKP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dim: int,\n",
    "                 num_ex: int,\n",
    "                 hidden: int = 256,\n",
    "                 ex_emb: int = 64):\n",
    "        super().__init__()\n",
    "        # keypoint feature extractor\n",
    "        self.encoder = KeypointEncoder(in_dim)\n",
    "\n",
    "        # sequence model\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=512,\n",
    "            hidden_size=hidden,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        feat_dim = hidden * 2\n",
    "\n",
    "        # exercise embedding MLP\n",
    "        self.ex_emb = nn.Sequential(\n",
    "            nn.Linear(num_ex, ex_emb),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ex_emb, ex_emb)\n",
    "        )\n",
    "\n",
    "        # final heads\n",
    "        self.cls_head = nn.Linear(feat_dim + ex_emb, 2)\n",
    "        self.err_head = nn.Linear(feat_dim + ex_emb, N_ERR)\n",
    "\n",
    "    def forward(self,\n",
    "                seq:     torch.Tensor,  # (B, T, D)\n",
    "                ex_1hot: torch.Tensor   # (B, num_ex)\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        # 1) keypoint → sequence feats\n",
    "        # encode each frame\n",
    "        B,T,_ = seq.shape\n",
    "        feats = torch.stack([\n",
    "            self.encoder(seq[:,t]) for t in range(T)\n",
    "        ], dim=1)                                # (B, T, 512)\n",
    "        out, _ = self.lstm(feats)                # (B, T, 2*hidden)\n",
    "        g = out.mean(1)                          # (B, 2*hidden)\n",
    "\n",
    "        # 2) exercise embed\n",
    "        ex_e = self.ex_emb(ex_1hot)              # (B, ex_emb)\n",
    "\n",
    "        # 3) concat and heads\n",
    "        h = torch.cat([g, ex_e], dim=1)          # (B, feat_dim+ex_emb)\n",
    "        return self.cls_head(h), self.err_head(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fa0f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train_epochs(\n",
    "    csv_file:  str   = str(WIN_CSV),\n",
    "    keypt_root:str   = str(KEYPT_ROOT),\n",
    "    num_ex:    int   = NUM_EXERCISES,\n",
    "    epochs:    int   = 30,\n",
    "    batch:     int   = 16,\n",
    "    lr:        float = 1e-4,\n",
    "    ckpt_file: str   = CKPT_FILE\n",
    "):\n",
    "    # Build dataset and split\n",
    "    ds  = KeypointWindowDataset(Path(csv_file), Path(keypt_root))\n",
    "    N   = len(ds)\n",
    "    idx = np.arange(N); np.random.shuffle(idx)\n",
    "    c1, c2 = int(0.7*N), int(0.85*N)\n",
    "    train_idx, val_idx = idx[:c1], idx[c1:c2]\n",
    "\n",
    "    train_dl = DataLoader(Subset(ds, train_idx), batch_size=batch, shuffle=True)\n",
    "    val_dl   = DataLoader(Subset(ds, val_idx),   batch_size=batch, shuffle=False)\n",
    "\n",
    "    # Infer input dimension\n",
    "    sample_seq, _, _, _ = ds[0]\n",
    "    in_dim = sample_seq.shape[-1]\n",
    "\n",
    "    # Build model\n",
    "    model    = PoseQualityNetKP(in_dim, num_ex).to(DEVICE)\n",
    "    loss_cls = nn.CrossEntropyLoss()\n",
    "    loss_err = nn.SmoothL1Loss()\n",
    "    opt      = Adam(model.parameters(), lr)\n",
    "\n",
    "    best_f1 = 0.0\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # -- train --\n",
    "        model.train()\n",
    "        tot_loss = 0.0\n",
    "        for seq, y, err, ex in tqdm(train_dl, desc=f\"Epoch {epoch:02d}\"):\n",
    "            seq, y, err, ex = [x.to(DEVICE) for x in (seq, y, err, ex)]\n",
    "            # Build one-hot encoding for exercise\n",
    "            ex_1hot = F.one_hot(ex, num_ex).float()\n",
    "\n",
    "            opt.zero_grad()\n",
    "            logits, err_hat = model(seq, ex_1hot)\n",
    "            loss = loss_cls(logits, y) + 0.1 * loss_err(err_hat, err)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            tot_loss += loss.item() * y.size(0)\n",
    "        print(f\"  ↳ train loss: {tot_loss/len(train_idx):.4f}\")\n",
    "\n",
    "        # -- validation --\n",
    "        model.eval()\n",
    "        y_true, y_pred, errs = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for seq, y, err, ex in val_dl:\n",
    "                seq, y, err, ex = [x.to(DEVICE) for x in (seq, y, err, ex)]\n",
    "                ex_1hot = F.one_hot(ex, num_ex).float()\n",
    "                logits, err_hat = model(seq, ex_1hot)\n",
    "\n",
    "                y_true += y.cpu().tolist()\n",
    "                y_pred += logits.argmax(1).cpu().tolist()\n",
    "                errs    += [(err_hat - err.to(DEVICE)).abs().mean(1)]\n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        f1  = f1_score(y_true, y_pred)\n",
    "        mae = torch.cat(errs).mean().item()\n",
    "        print(f\"  ↳ val acc {acc:.3f}, F1 {f1:.3f}, MAE° {mae:.2f}\")\n",
    "\n",
    "        # Save the model with the best F1 score\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            # Save the entire model (including architecture and weights)\n",
    "            torch.save(model, ckpt_file)  # Save the entire model\n",
    "            print(f\"  ✓ saved new best model to {ckpt_file}  (F1 {f1:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2c78881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01:  40%|███▉      | 249/629 [00:05<00:08, 46.17it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mtrain_epochs\u001b[39m\u001b[34m(csv_file, keypt_root, num_ex, epochs, batch, lr, ckpt_file)\u001b[39m\n\u001b[32m     42\u001b[39m logits, err_hat = model(seq, ex_1hot)\n\u001b[32m     43\u001b[39m loss = loss_cls(logits, y) + \u001b[32m0.1\u001b[39m * loss_err(err_hat, err)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m opt.step()\n\u001b[32m     47\u001b[39m tot_loss += loss.item() * y.size(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/rehabtrainingpy312/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    572\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    573\u001b[39m         Tensor.backward,\n\u001b[32m    574\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    579\u001b[39m         inputs=inputs,\n\u001b[32m    580\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m581\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/rehabtrainingpy312/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/rehabtrainingpy312/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    823\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    826\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_epochs(epochs=50, batch=16, lr=1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rehabtrainingpy312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
