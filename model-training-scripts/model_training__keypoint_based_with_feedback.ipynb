{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ed50409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOINT_NAMES: ['NOSE', 'LEFT_EYE_INNER', 'LEFT_EYE', 'LEFT_EYE_OUTER', 'RIGHT_EYE_INNER', 'RIGHT_EYE', 'RIGHT_EYE_OUTER', 'LEFT_EAR', 'RIGHT_EAR', 'MOUTH_LEFT', 'MOUTH_RIGHT', 'LEFT_SHOULDER', 'RIGHT_SHOULDER', 'LEFT_ELBOW', 'RIGHT_ELBOW', 'LEFT_WRIST', 'RIGHT_WRIST', 'LEFT_PINKY', 'RIGHT_PINKY', 'LEFT_INDEX', 'RIGHT_INDEX', 'LEFT_THUMB', 'RIGHT_THUMB', 'LEFT_HIP', 'RIGHT_HIP', 'LEFT_KNEE', 'RIGHT_KNEE', 'LEFT_ANKLE', 'RIGHT_ANKLE', 'LEFT_HEEL', 'RIGHT_HEEL', 'LEFT_FOOT_INDEX', 'RIGHT_FOOT_INDEX']\n",
      "N_JOINTS: 33\n"
     ]
    }
   ],
   "source": [
    "# 0. Imports\n",
    "from __future__ import annotations\n",
    "import os, random, warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "import mediapipe as mp\n",
    "\n",
    "# Replace this failing line:\n",
    "# from mediapipe.solutions.pose import PoseLandmark\n",
    "\n",
    "# With:\n",
    "PoseLandmark = mp.solutions.pose.PoseLandmark\n",
    "\n",
    "# Then:\n",
    "JOINT_NAMES = [lm.name for lm in PoseLandmark]\n",
    "N_JOINTS    = len(JOINT_NAMES)  # should be 33\n",
    "\n",
    "print(f\"JOINT_NAMES: {JOINT_NAMES}\")\n",
    "print(f\"N_JOINTS: {N_JOINTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f3eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "► Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# 1. Paths & device\n",
    "SCRIPT_DIR     = Path(os.getcwd()).resolve()\n",
    "META_FILE      = SCRIPT_DIR / \"Data-REHAB24-6\" / \"Segmentation.xlsx\"\n",
    "KEYPOINT_ROOT  = SCRIPT_DIR / \"Data-REHAB24-6\" / \"mp_keypoints\"\n",
    "\n",
    "DEVICE = (\n",
    "    torch.device(\"mps\") if torch.backends.mps.is_available() else\n",
    "    torch.device(\"cuda\") if torch.cuda.is_available() else\n",
    "    torch.device(\"cpu\")\n",
    ")\n",
    "print(\"► Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97531384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved MediaPipe joint names to /Users/jithinkrishnan/Documents/Study/IS06 /MVP/RehabApp/model-training-scripts/Data-REHAB24-6/mp_keypoints/mediapipe_joint_names.txt\n"
     ]
    }
   ],
   "source": [
    "# 2. Joint names & count\n",
    "JOINT_NAMES = [jl.name for jl in PoseLandmark]\n",
    "N_JOINTS    = len(JOINT_NAMES)   # 33\n",
    "# save them for reference\n",
    "names_file = KEYPOINT_ROOT / \"mediapipe_joint_names.txt\"\n",
    "KEYPOINT_ROOT.mkdir(exist_ok=True)\n",
    "with open(names_file, \"w\") as f:\n",
    "    for i, name in enumerate(JOINT_NAMES):\n",
    "        f.write(f\"{i}: {name}\\n\")\n",
    "print(\"✔ Saved MediaPipe joint names to\", names_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "068a19c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feedback helper\n",
    "import math\n",
    "\n",
    "# friendly names for a few key joints (you can extend this)\n",
    "FRIENDLY = {\n",
    "    \"LEFT_ELBOW\":     \"left elbow\",\n",
    "    \"RIGHT_ELBOW\":    \"right elbow\",\n",
    "    \"LEFT_SHOULDER\":  \"left shoulder\",\n",
    "    \"RIGHT_SHOULDER\": \"right shoulder\",\n",
    "    \"LEFT_KNEE\":      \"left knee\",\n",
    "    \"RIGHT_KNEE\":     \"right knee\",\n",
    "    \"SPINE\":          \"spine\",\n",
    "    \"NOSE\":           \"head\",\n",
    "    # etc…\n",
    "}\n",
    "\n",
    "# for each body part keyword, tuple = (verb if err<0, verb if err>0)\n",
    "ACTION_VERBS = {\n",
    "    \"elbow\":    (\"flex\",        \"extend\"),\n",
    "    \"shoulder\": (\"rotate back\", \"rotate forward\"),\n",
    "    \"knee\":     (\"bend\",        \"straighten\"),\n",
    "    \"hip\":      (\"lower\",       \"lift\"),\n",
    "    \"spine\":    (\"arch\",        \"tuck\"),\n",
    "    # fallback will be (\"move\", \"move\")\n",
    "}\n",
    "\n",
    "def magnitude_adverb(deg: float) -> str:\n",
    "    a = abs(deg)\n",
    "    if a < 5:   return \"slightly\"\n",
    "    if a < 15:  return \"noticeably\"\n",
    "    return        \"significantly\"\n",
    "\n",
    "def get_action(part: str, deg: float) -> str:\n",
    "    part = part.lower()\n",
    "    for key, (neg, pos) in ACTION_VERBS.items():\n",
    "        if key in part:\n",
    "            return neg if deg < 0 else pos\n",
    "    return \"move\"  # generic fallback\n",
    "\n",
    "def english_feedback(err_vec: list[float], tol: float = 5.0) -> list[str]:\n",
    "    # pick joints with error > tol\n",
    "    joints = [(j, deg) for j, deg in enumerate(err_vec) if abs(deg) > tol]\n",
    "    if not joints:\n",
    "        return [\"✅ Perfect form! Hold that posture.\"]\n",
    "\n",
    "    # sort by largest error first, keep top 3\n",
    "    joints = sorted(joints, key=lambda x: abs(x[1]), reverse=True)[:3]\n",
    "\n",
    "    tips = []\n",
    "    for j, deg in joints:\n",
    "        name = JOINT_NAMES[j]\n",
    "        part = FRIENDLY.get(name, name.lower().replace(\"_\", \" \"))\n",
    "        adv  = magnitude_adverb(deg).capitalize()\n",
    "        verb = get_action(part, deg)\n",
    "        tips.append(f\"{adv} {verb} your {part} by {abs(deg):.1f}°\")\n",
    "    return tips\n",
    "\n",
    "# — example usage —\n",
    "# err_vec = [0, -12.3, 3.1, 20.5, …]  # degrees off for each JOINT_NAMES entry\n",
    "# print(english_feedback(err_vec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a911cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Dataset\n",
    "class KeypointDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 keypt_root: Path,\n",
    "                 meta:       Path,\n",
    "                 frames:     int = 16,\n",
    "                 split:      str = \"train\"):\n",
    "        # load metadata (xlsx or csv)\n",
    "        ext = meta.suffix.lower()\n",
    "        if ext in (\".xlsx\", \".xls\"):\n",
    "            df = pd.read_excel(meta, engine=\"openpyxl\")\n",
    "        else:\n",
    "            df = pd.read_csv(meta, skipinitialspace=True)\n",
    "        df.columns = df.columns.str.strip()\n",
    "\n",
    "        # ensure error‑columns exist\n",
    "        err_cols = [f\"err_{i}\" for i in range(N_JOINTS)]\n",
    "        if not all(c in df.columns for c in err_cols):\n",
    "            warnings.warn(\"err_0…err_NJOINTS not found → filling zeros\")\n",
    "            for c in err_cols:\n",
    "                df[c] = 0.0\n",
    "\n",
    "        # split video_ids\n",
    "        vids = sorted(df[\"video_id\"].unique())\n",
    "        random.shuffle(vids)\n",
    "        a, b = int(0.7*len(vids)), int(0.85*len(vids))\n",
    "        keep = (\n",
    "            vids[:a]   if split==\"train\" else\n",
    "            vids[a:b]  if split==\"val\"   else\n",
    "            vids[b:]\n",
    "        )\n",
    "        self.meta       = df[df.video_id.isin(keep)].reset_index(drop=True)\n",
    "        self.err_cols   = err_cols\n",
    "        self.frames     = frames\n",
    "        self.keypt_root = keypt_root\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row    = self.meta.iloc[idx]\n",
    "        ex_dir = self.keypt_root / f\"Ex{row.exercise_id}\"\n",
    "\n",
    "        # pick Camera17 file by globbing\n",
    "        pattern = f\"{row.video_id}-Camera17*-mp.npy\"\n",
    "        files = list(ex_dir.glob(pattern))\n",
    "        if not files:\n",
    "            raise FileNotFoundError(f\"No Camera17 MP file matching {pattern} in {ex_dir}\")\n",
    "        if len(files) > 1:\n",
    "            # unlikely, but guard against duplicates\n",
    "            files = sorted(files)\n",
    "        mp_file = files[0]\n",
    "\n",
    "        # load & reshape\n",
    "        arr = np.load(mp_file)        # (F, N_JOINTS, 3)\n",
    "        F, L, C = arr.shape\n",
    "        assert C == 3 and L == N_JOINTS, f\"Expected (F,{N_JOINTS},3), got {arr.shape}\"\n",
    "        arr = arr.reshape(F, L*C)     # → (F, N_JOINTS*3)\n",
    "\n",
    "        # sample T frames\n",
    "        tot  = arr.shape[0]\n",
    "        idxs = torch.linspace(0, tot-1, self.frames).long()\n",
    "        seq  = torch.from_numpy(arr[idxs]).float()  # (T, N_JOINTS*3)\n",
    "\n",
    "        # labels & errors\n",
    "        label    = torch.tensor(row.correctness, dtype=torch.long)\n",
    "        err_vals = row[self.err_cols].to_numpy(dtype=np.float32)\n",
    "        err      = torch.tensor(err_vals, dtype=torch.float32)\n",
    "\n",
    "        return seq, label, err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71a49b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Model definitions\n",
    "class KeypointEncoder(nn.Module):\n",
    "    def __init__(self, in_dim: int, embed: int = 512):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_dim, 128, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(128, embed, kernel_size=3, padding=1)\n",
    "        self.pool  = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.transpose(1,2)               # (B, D, T)\n",
    "        # x is (B, D); treat it as (B, D, 1) so Conv1d can run over that “length=1”\n",
    "        x = x.unsqueeze(2)                # → (B, D, 1)\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        return self.pool(x).squeeze(-1)    # (B, embed)\n",
    "\n",
    "class PoseQualityNetKP(nn.Module):\n",
    "    def __init__(self, in_dim: int, hidden: int = 256):\n",
    "        super().__init__()\n",
    "        self.encoder  = KeypointEncoder(in_dim)\n",
    "        self.lstm     = nn.LSTM(\n",
    "            input_size=512,\n",
    "            hidden_size=hidden,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        dim = hidden*2\n",
    "        self.cls_head = nn.Linear(dim, 2)\n",
    "        self.err_head = nn.Linear(dim, N_JOINTS)\n",
    "\n",
    "    def forward(self, seq):\n",
    "        # seq: (B, T, D)\n",
    "        feats = torch.stack([\n",
    "            self.encoder(seq[:, t]) for t in range(seq.size(1))\n",
    "        ], dim=1)                         # (B, T, 512)\n",
    "        out, _ = self.lstm(feats)         # (B, T, 2*hidden)\n",
    "        g = out.mean(1)                   # (B, 2*hidden)\n",
    "        return self.cls_head(g), self.err_head(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fa0f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Training loop\n",
    "def train_epochs(\n",
    "    epochs:    int = 30,\n",
    "    batch:     int = 16,\n",
    "    lr:        float = 1e-4,\n",
    "    ckpt_file: str = \"kp_pose_quality_mp.pt\"\n",
    "):\n",
    "    train_ds = KeypointDataset(KEYPOINT_ROOT, META_FILE, split=\"train\")\n",
    "    val_ds   = KeypointDataset(KEYPOINT_ROOT, META_FILE, split=\"val\")\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch, shuffle=True)\n",
    "    val_dl   = DataLoader(val_ds,   batch_size=batch, shuffle=False)\n",
    "\n",
    "    # infer input dim\n",
    "    sample_seq, _, _ = train_ds[0]\n",
    "    in_dim = sample_seq.shape[-1]  # 33*3 = 99\n",
    "\n",
    "    model    = PoseQualityNetKP(in_dim).to(DEVICE)\n",
    "    loss_cls = nn.CrossEntropyLoss()\n",
    "    loss_err = nn.SmoothL1Loss()\n",
    "    opt      = Adam(model.parameters(), lr)\n",
    "    best_f1  = 0.0\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        for seq, y, err in tqdm(train_dl, desc=f\"Epoch {epoch:02d}\"):\n",
    "            seq, y, err = seq.to(DEVICE), y.to(DEVICE), err.to(DEVICE)\n",
    "            opt.zero_grad()\n",
    "            logits, err_hat = model(seq)\n",
    "            loss = loss_cls(logits, y) + 0.1*loss_err(err_hat, err)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total_loss += loss.item() * y.size(0)\n",
    "        print(f\"  ↳ train loss: {total_loss/len(train_ds):.4f}\")\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        y_true, y_pred, errs = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for seq, y, err in val_dl:\n",
    "                logits, err_hat = model(seq.to(DEVICE))\n",
    "                y_true += y.tolist()\n",
    "                y_pred += logits.argmax(1).cpu().tolist()\n",
    "                errs    += [torch.abs(err_hat.cpu() - err).mean(1)]\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        f1  = f1_score(y_true, y_pred)\n",
    "        mae = torch.cat(errs).mean().item()\n",
    "        print(f\"  ↳ val acc {acc:.3f}, F1 {f1:.3f}, MAE° {mae:.2f}\")\n",
    "\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "\n",
    "            # package checkpoint with everything needed to rebuild & infer\n",
    "            checkpoint = {\n",
    "                \"state_dict\": model.state_dict(),\n",
    "                \"input_dim\":  in_dim,\n",
    "                \"hidden\":     model.lstm.hidden_size,\n",
    "                \"frames\":     train_ds.frames,\n",
    "                \"epoch\":      epoch,\n",
    "                \"best_f1\":    best_f1\n",
    "            }\n",
    "\n",
    "            torch.save(checkpoint, ckpt_file)\n",
    "            print(f\"  ✓ saved new best model to {ckpt_file}  (epoch {epoch}, F1 {f1:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2c78881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pv/99z70cjs7t1dx16_0r1c33hw0000gn/T/ipykernel_23368/1680097000.py:19: UserWarning: err_0…err_NJOINTS not found → filling zeros\n",
      "  warnings.warn(\"err_0…err_NJOINTS not found → filling zeros\")\n",
      "/var/folders/pv/99z70cjs7t1dx16_0r1c33hw0000gn/T/ipykernel_23368/1680097000.py:19: UserWarning: err_0…err_NJOINTS not found → filling zeros\n",
      "  warnings.warn(\"err_0…err_NJOINTS not found → filling zeros\")\n",
      "Epoch 01: 100%|██████████| 46/46 [00:01<00:00, 36.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6925\n",
      "  ↳ val acc 0.486, F1 0.654, MAE° 0.00\n",
      "  ✓ saved new best model to kp_pose_quality_mp.pt  (epoch 1, F1 0.654)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02: 100%|██████████| 46/46 [00:00<00:00, 50.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6935\n",
      "  ↳ val acc 0.486, F1 0.654, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03: 100%|██████████| 46/46 [00:00<00:00, 46.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6919\n",
      "  ↳ val acc 0.486, F1 0.654, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04: 100%|██████████| 46/46 [00:01<00:00, 45.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6913\n",
      "  ↳ val acc 0.486, F1 0.654, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05: 100%|██████████| 46/46 [00:01<00:00, 45.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6895\n",
      "  ↳ val acc 0.486, F1 0.654, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06: 100%|██████████| 46/46 [00:01<00:00, 45.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6836\n",
      "  ↳ val acc 0.549, F1 0.557, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 07: 100%|██████████| 46/46 [00:00<00:00, 48.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6748\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 08: 100%|██████████| 46/46 [00:00<00:00, 49.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6776\n",
      "  ↳ val acc 0.549, F1 0.621, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 09: 100%|██████████| 46/46 [00:00<00:00, 49.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6708\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 46/46 [00:00<00:00, 50.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6716\n",
      "  ↳ val acc 0.549, F1 0.621, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 46/46 [00:00<00:00, 50.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6671\n",
      "  ↳ val acc 0.549, F1 0.602, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 46/46 [00:00<00:00, 49.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6693\n",
      "  ↳ val acc 0.549, F1 0.602, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 46/46 [00:00<00:00, 49.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6668\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 46/46 [00:00<00:00, 49.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6697\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 46/46 [00:00<00:00, 49.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6671\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 46/46 [00:00<00:00, 50.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6692\n",
      "  ↳ val acc 0.549, F1 0.557, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 46/46 [00:00<00:00, 49.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6661\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 46/46 [00:00<00:00, 49.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6669\n",
      "  ↳ val acc 0.549, F1 0.557, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 46/46 [00:00<00:00, 50.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6670\n",
      "  ↳ val acc 0.549, F1 0.557, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 46/46 [00:00<00:00, 50.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6659\n",
      "  ↳ val acc 0.549, F1 0.581, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 46/46 [00:00<00:00, 50.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6646\n",
      "  ↳ val acc 0.549, F1 0.557, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 46/46 [00:00<00:00, 50.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6643\n",
      "  ↳ val acc 0.549, F1 0.557, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 46/46 [00:00<00:00, 49.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6668\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 46/46 [00:00<00:00, 49.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6637\n",
      "  ↳ val acc 0.671, F1 0.607, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 46/46 [00:00<00:00, 50.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6673\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 46/46 [00:00<00:00, 50.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6647\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 46/46 [00:00<00:00, 49.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6635\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 46/46 [00:00<00:00, 50.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6647\n",
      "  ↳ val acc 0.549, F1 0.557, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 46/46 [00:00<00:00, 50.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6633\n",
      "  ↳ val acc 0.549, F1 0.557, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 46/46 [00:00<00:00, 50.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6635\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 46/46 [00:00<00:00, 50.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6627\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 46/46 [00:00<00:00, 50.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6611\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 46/46 [00:00<00:00, 49.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6613\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 46/46 [00:00<00:00, 47.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6644\n",
      "  ↳ val acc 0.543, F1 0.652, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 46/46 [00:00<00:00, 49.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6613\n",
      "  ↳ val acc 0.549, F1 0.557, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 46/46 [00:00<00:00, 48.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6622\n",
      "  ↳ val acc 0.549, F1 0.581, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 46/46 [00:00<00:00, 49.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6615\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 46/46 [00:00<00:00, 48.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6611\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 46/46 [00:00<00:00, 48.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6597\n",
      "  ↳ val acc 0.543, F1 0.680, MAE° 0.00\n",
      "  ✓ saved new best model to kp_pose_quality_mp.pt  (epoch 39, F1 0.680)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 46/46 [00:00<00:00, 48.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6649\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 46/46 [00:00<00:00, 49.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6594\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 46/46 [00:00<00:00, 49.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6603\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 46/46 [00:00<00:00, 49.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6619\n",
      "  ↳ val acc 0.549, F1 0.557, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 46/46 [00:00<00:00, 49.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6600\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 46/46 [00:00<00:00, 49.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6599\n",
      "  ↳ val acc 0.543, F1 0.680, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 46/46 [00:00<00:00, 48.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6600\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 46/46 [00:00<00:00, 48.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6580\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 46/46 [00:00<00:00, 49.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6623\n",
      "  ↳ val acc 0.543, F1 0.652, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 46/46 [00:00<00:00, 49.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6586\n",
      "  ↳ val acc 0.549, F1 0.530, MAE° 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 46/46 [00:00<00:00, 49.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ↳ train loss: 0.6618\n",
      "  ↳ val acc 0.543, F1 0.578, MAE° 0.00\n"
     ]
    }
   ],
   "source": [
    "# 8. Run training\n",
    "train_epochs(epochs=50, batch=16, lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73b04bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1744977798.436367  716137 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.3), renderer: Apple M4 Max\n",
      "W0000 00:00:1744977798.487191  734105 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1744977798.509922  734111 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded. Starting live inference…\n",
      "▶ Press ESC to exit.\n",
      "[Frame 1] No landmarks\n",
      "[Frame 2] Buffered 1/16\n",
      "[Frame 3] Buffered 2/16\n",
      "[Frame 4] Buffered 3/16\n",
      "[Frame 5] Buffered 4/16\n",
      "[Frame 6] Buffered 5/16\n",
      "[Frame 7] Buffered 6/16\n",
      "[Frame 8] Buffered 7/16\n",
      "[Frame 9] Buffered 8/16\n",
      "[Frame 10] Buffered 9/16\n",
      "[Frame 11] Buffered 10/16\n",
      "[Frame 12] Buffered 11/16\n",
      "[Frame 13] Buffered 12/16\n",
      "[Frame 14] Buffered 13/16\n",
      "[Frame 15] Buffered 14/16\n",
      "[Frame 16] Buffered 15/16\n",
      "[Frame 17] Buffered 16/16\n",
      "▶ Buffer full — running inference\n",
      "   raw logits: [[-1.0874856  1.0430459]]\n",
      "   raw err (first 5): [-0.00043773  0.00259034 -0.00691423  0.01132228  0.00314515]\n",
      "   🎯 pred=1, tips=['✅ Perfect form! Hold that posture.']\n",
      "[Frame 18] Buffered 1/16\n",
      "[Frame 19] Buffered 2/16\n",
      "[Frame 20] Buffered 3/16\n",
      "[Frame 21] Buffered 4/16\n",
      "[Frame 22] Buffered 5/16\n",
      "[Frame 23] Buffered 6/16\n",
      "[Frame 24] Buffered 7/16\n",
      "❎ ESC pressed, exiting.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import deque\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe setup\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_styles  = mp.solutions.drawing_styles\n",
    "mp_pose    = mp.solutions.pose.Pose(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=2,\n",
    "    enable_segmentation=False,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# Load your feedback helper\n",
    "# from your_feedback_cell import english_feedback\n",
    "\n",
    "# Rebuild model (use weights_only=True to suppress the pickle warning)\n",
    "ckpt = torch.load('kp_pose_quality_mp.pt', map_location=DEVICE, weights_only=True)\n",
    "in_dim, hidden, frames = ckpt[\"input_dim\"], ckpt[\"hidden\"], ckpt[\"frames\"]\n",
    "infer_model = PoseQualityNetKP(in_dim, hidden).to(DEVICE)\n",
    "infer_model.load_state_dict(ckpt[\"state_dict\"])\n",
    "infer_model.eval()\n",
    "print(\"✅ Model loaded. Starting live inference…\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "buffer = deque(maxlen=frames)\n",
    "frame_count = 0\n",
    "\n",
    "print(\"▶ Press ESC to exit.\")\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame_count += 1\n",
    "    if not ret:\n",
    "        print(\"⚠️  Failed to grab frame, exiting.\")\n",
    "        break\n",
    "\n",
    "    # Prepare image for MediaPipe\n",
    "    h, w = frame.shape[:2]\n",
    "    rgb = cv2.cvtColor(cv2.flip(frame, 1), cv2.COLOR_BGR2RGB)\n",
    "    rgb.flags.writeable = False\n",
    "    results = mp_pose.process(rgb)  # IMAGE_DIMENSIONS warning can be ignored\n",
    "    rgb.flags.writeable = True\n",
    "\n",
    "    img = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        # Draw skeleton\n",
    "        mp_drawing.draw_landmarks(\n",
    "            img, results.pose_landmarks, mp.solutions.pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=mp_styles.get_default_pose_landmarks_style()\n",
    "        )\n",
    "        # Extract and buffer keypoints\n",
    "        arr = np.array([[lm.x, lm.y, lm.z]\n",
    "                        for lm in results.pose_landmarks.landmark],\n",
    "                       dtype=np.float32).reshape(-1)\n",
    "        buffer.append(arr)\n",
    "        print(f\"[Frame {frame_count}] Buffered {len(buffer)}/{frames}\")\n",
    "    else:\n",
    "        print(f\"[Frame {frame_count}] No landmarks\")\n",
    "\n",
    "    # When buffer is full, run inference\n",
    "    if len(buffer) == frames:\n",
    "        print(\"▶ Buffer full — running inference\")\n",
    "        seq = torch.tensor(np.stack(buffer), dtype=torch.float32).unsqueeze(0).to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            logits, err_hat = infer_model(seq)\n",
    "        # Debug print raw outputs\n",
    "        print(\"   raw logits:\", logits.cpu().numpy())\n",
    "        print(\"   raw err (first 5):\", err_hat.squeeze(0).cpu().numpy()[:5])\n",
    "\n",
    "        pred = logits.argmax(1).item()\n",
    "        tips = english_feedback(err_hat.squeeze(0).cpu().numpy())\n",
    "        print(f\"   🎯 pred={pred}, tips={tips}\")\n",
    "\n",
    "        # Overlay tips on image\n",
    "        color = (0,255,0) if pred == 1 else (0,0,255)\n",
    "        for i, tip in enumerate(tips):\n",
    "            cv2.putText(img, tip, (10, 30 + 30*i),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "\n",
    "        # Clear buffer so next window is fresh\n",
    "        buffer.clear()\n",
    "\n",
    "    else:\n",
    "        # Show buffering progress\n",
    "        cv2.putText(img,\n",
    "                    f\"Buffering keypoints: {len(buffer)}/{frames}\",\n",
    "                    (10,30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8,\n",
    "                    (200,200,0), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"Live Pose Feedback\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        print(\"❎ ESC pressed, exiting.\")\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rehabtrainingpy312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
